{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mratanusarkar/twitter-sentiment-analysis/blob/feature%2Ftweet-analysis-and-inference/Tweet_Analysis_and_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssub8kuSzNTn"
      },
      "source": [
        "# Tweet Analysis and Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Packages"
      ],
      "metadata": {
        "id": "jF-VGO034JtD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fshsilWazExT"
      },
      "outputs": [],
      "source": [
        "!pip install snscrape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW4ht4QpzTiG"
      },
      "outputs": [],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import traceback\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8HkWssaA4M6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Helper Functions"
      ],
      "metadata": {
        "id": "lEVuSTAv4NpA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FS0cz6nVzVPv"
      },
      "outputs": [],
      "source": [
        "def get_tweets(query: str, limit: int) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Scrape tweets from twitter based on input search query\n",
        "    Arguments:\n",
        "        :param query: twitter search query as per https://twitter.com/search?q=\n",
        "        :param limit: number of tweets you want to scrape\n",
        "    Returns:\n",
        "        :return: a pandas dataframe with the tweets\n",
        "    \"\"\"\n",
        "    tweets = []\n",
        "    columns = [\n",
        "        'id',\n",
        "        'date',\n",
        "        'username',\n",
        "        'content',\n",
        "        'view_count',\n",
        "        'like_count',\n",
        "        'reply_count',\n",
        "        'retweet_count',\n",
        "        'quote_Count',\n",
        "        'url'\n",
        "    ]\n",
        "    try:  \n",
        "        twitter_search = sntwitter.TwitterSearchScraper(query).get_items()\n",
        "        for tweet in tqdm(twitter_search, total=limit):\n",
        "            if len(tweets) == limit:\n",
        "                break\n",
        "            else:\n",
        "                data = [\n",
        "                    tweet.id,\n",
        "                    tweet.date,\n",
        "                    tweet.user.username,\n",
        "                    tweet.rawContent,\n",
        "                    tweet.viewCount,\n",
        "                    tweet.likeCount,\n",
        "                    tweet.replyCount,\n",
        "                    tweet.retweetCount,\n",
        "                    tweet.quoteCount,\n",
        "                    tweet.url\n",
        "                ]\n",
        "                tweets.append(data)\n",
        "        df = pd.DataFrame(tweets, columns=columns)\n",
        "        return df\n",
        "    except Exception:\n",
        "        print(traceback.print_exc())\n",
        "        return pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def refine_text(tweet: str) -> str:\n",
        "    tweet_words = []\n",
        "    for word in tweet.split(' '):\n",
        "        if word.startswith('@') and len(word) > 1:\n",
        "            word = \"\"\n",
        "        elif word.startswith('http') or word.startswith('www'):\n",
        "            word = \"\"\n",
        "        tweet_words.append(word)\n",
        "    \n",
        "    refined_tweet = \" \".join(tweet_words)\n",
        "    \n",
        "    exclude = set(string.punctuation)\n",
        "    refined_tweet = ''.join(ch for ch in refined_tweet if ch not in exclude)\n",
        "    \n",
        "    return refined_tweet"
      ],
      "metadata": {
        "id": "zUt8I5qd4epk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjtNAdjTzatz"
      },
      "outputs": [],
      "source": [
        "def word_counter(tweet: str, counter: Counter) -> Counter:\n",
        "    word_list = tweet.split(' ')\n",
        "    word_count = Counter(word_list)\n",
        "    return counter + word_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nzgbmK6zawL"
      },
      "outputs": [],
      "source": [
        "def remove_common_words(counter: Counter) -> Counter:\n",
        "    # https://www.textfixer.com/tutorials/common-english-words.php\n",
        "    common_words = [\n",
        "        \"\", \"'tis\", \"'twas\", \"a\", \"able\", \"about\", \"across\", \"after\", \"ain't\", \n",
        "        \"all\", \"almost\", \"also\", \"am\", \"among\", \"an\", \"and\", \"any\", \"are\", \"aren't\", \n",
        "        \"as\", \"at\", \"be\", \"because\", \"been\", \"but\", \"by\", \"can\", \"can't\", \"cannot\", \n",
        "        \"could\", \"could've\", \"couldn't\", \"dear\", \"did\", \"didn't\", \"do\", \"does\", \n",
        "        \"doesn't\", \"don't\", \"either\", \"else\", \"ever\", \"every\", \"for\", \"from\", \"get\", \n",
        "        \"got\", \"had\", \"has\", \"hasn't\", \"have\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \n",
        "        \"hers\", \"him\", \"his\", \"how\", \"how'd\", \"how'll\", \"how's\", \"however\", \"i\", \n",
        "        \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \"it's\", \n",
        "        \"its\", \"just\", \"least\", \"let\", \"like\", \"likely\", \"may\", \"me\", \"might\", \"might've\", \n",
        "        \"mightn't\", \"most\", \"must\", \"must've\", \"mustn't\", \"my\", \"neither\", \"no\", \"nor\", \n",
        "        \"not\", \"of\", \"off\", \"often\", \"on\", \"only\", \"or\", \"other\", \"our\", \"own\", \"rather\", \n",
        "        \"said\", \"say\", \"says\", \"shan't\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
        "        \"should've\", \"shouldn't\", \"since\", \"so\", \"some\", \"than\", \"that\", \"that'll\", \n",
        "        \"that's\", \"the\", \"their\", \"them\", \"then\", \"there\", \"there's\", \"these\", \"they\", \n",
        "        \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"tis\", \"to\", \"too\", \"twas\", \n",
        "        \"us\", \"wants\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"were\", \"weren't\", \n",
        "        \"what\", \"what'd\", \"what's\", \"when\", \"when\", \"when'd\", \"when'll\", \"when's\", \"where\", \n",
        "        \"where'd\", \"where'll\", \"where's\", \"which\", \"while\", \"who\", \"who'd\", \"who'll\", \n",
        "        \"who's\", \"whom\", \"why\", \"why'd\", \"why'll\", \"why's\", \"will\", \"with\", \"won't\", \n",
        "        \"would\", \"would've\", \"wouldn't\", \"yet\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\"]\n",
        "\n",
        "    for common_word in common_words:\n",
        "        try:\n",
        "            counter.pop(common_word)\n",
        "        except:\n",
        "            pass\n",
        "    print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfdVaZiTza0M"
      },
      "outputs": [],
      "source": [
        "def generate_word_cloud(rawData: pd.DataFrame):\n",
        "    counter = Counter({})\n",
        "    for tweet_content in rawData.content:\n",
        "        refined_tweet = refine_text(tweet_content)\n",
        "        counter = word_counter(refined_tweet, counter)\n",
        "    counter = remove_common_words(counter)\n",
        "    print(counter)\n",
        "\n",
        "    wordcloud = WordCloud(width = 1000, height = 500).generate_from_frequencies(counter)\n",
        "    plt.figure(figsize=(15,8))\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    return plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XcGzZk7p4w0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Runner"
      ],
      "metadata": {
        "id": "gDDMUmWb52_z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ln-mvrGKzXO_"
      },
      "outputs": [],
      "source": [
        "# set parameters\n",
        "topic_title = 'ISRO_SSLVD2_Launch'\n",
        "query = 'ISRO (#SSLVD2 OR #ISRO)'\n",
        "limit = 1000\n",
        "\n",
        "# scrape tweets and generate wordcloud\n",
        "rawData = get_tweets(query, limit)\n",
        "plt = generate_word_cloud(rawData)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ocOrH8NK58qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export Data"
      ],
      "metadata": {
        "id": "ZJRCXgEL587P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ymnlT6LzXT3"
      },
      "outputs": [],
      "source": [
        "# Save Tweets\n",
        "rawData.to_csv(topic_title + \".csv\")\n",
        "rawData.to_json(topic_title + \".json\")\n",
        "rawData.to_parquet(topic_title + \".parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fP2w7orzXRn"
      },
      "outputs": [],
      "source": [
        "# Save Word Cloud\n",
        "plt.savefig(topic_title + \".png\", bbox_inches='tight')\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1o_7pQYzXdf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFQIGBys6yp1MoU1WkJV+T",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}